import os, json, urllib.request, urllib.parse, pandas as pd
from dotenv import load_dotenv
from time import sleep
import re

# ë°ì´í„° ìˆ˜ì§‘í•˜ëŠ” íŒŒì¼ 
load_dotenv()
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

regions = ["ì„œìš¸", "ë¶€ì‚°", "ì¸ì²œ", "ëŒ€ì „", "ê´‘ì£¼"]
categories = ["ë³´ìŒˆ", "ì¹´í˜", "í•œì‹", "ìˆ ì§‘", "ë¶„ì‹", "ì¤‘ì‹", "ì–‘ì‹"]

queries = []
for region in regions:
    for cat in categories:
        queries.append({'query': f'{region} {cat}', 'region': region, 'category': cat})
queries.append({'query': 'ëª…ì§€ëŒ€ ë¶€ê·¼ ë§›ì§‘', 'region': 'ì„œìš¸', 'category': 'ë§›ì§‘'})

# ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ë‚¨ê°€ì¢Œë™ ë° ëª…ì§€ëŒ€(ì„œìš¸ì¸ë¬¸ìº ) ìœ„ì£¼ë¡œ ì¿¼ë¦¬ ì¶”ê°€
queries.append({'query': 'ë‚¨ê°€ì¢Œë™ ë§›ì§‘', 'region': 'ì„œìš¸', 'category': 'ë§›ì§‘'})
queries.append({'query': 'ë‚¨ê°€ì¢Œë™ ë³´ìŒˆ', 'region': 'ì„œìš¸', 'category': 'ë³´ìŒˆ'})
queries.append({'query': 'ë‚¨ê°€ì¢Œë™ ì¹´í˜', 'region': 'ì„œìš¸', 'category': 'ì¹´í˜'})
queries.append({'query': 'ë‚¨ê°€ì¢Œë™ í•œì‹', 'region': 'ì„œìš¸', 'category': 'í•œì‹'})
queries.append({'query': 'ë‚¨ê°€ì¢Œë™ ìˆ ì§‘', 'region': 'ì„œìš¸', 'category': 'ìˆ ì§‘'})
queries.append({'query': 'ë‚¨ê°€ì¢Œë™ ë¶„ì‹', 'region': 'ì„œìš¸', 'category': 'ë¶„ì‹'})
queries.append({'query': 'ë‚¨ê°€ì¢Œë™ ì¤‘ì‹', 'region': 'ì„œìš¸', 'category': 'ì¤‘ì‹'})
queries.append({'query': 'ë‚¨ê°€ì¢Œë™ ì–‘ì‹', 'region': 'ì„œìš¸', 'category': 'ì–‘ì‹'})
queries.append({'query': 'ëª…ì§€ëŒ€ ì¸ë¬¸ìº  ë§›ì§‘', 'region': 'ì„œìš¸', 'category': 'ë§›ì§‘'})
queries.append({'query': 'ëª…ì§€ëŒ€ ë§›ì§‘', 'region': 'ì„œìš¸', 'category': 'ë§›ì§‘'})


def search_naver_blog(query, start=1, display=100):
    encText = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/blog.json?query={encText}&display={display}&start={start}"
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
    request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    response = urllib.request.urlopen(request)
    return json.loads(response.read().decode('utf-8'))

if __name__ == "__main__":
    all_posts = []
    for q_info in queries:
        query = q_info['query']
        region = q_info['region']
        cat = q_info['category']
        print(f"ğŸ” '{query}' ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        for start in range(1, 1001, 100):  # 1~1000ê¹Œì§€ 100ë‹¨ìœ„ í˜ì´ì§€
            try:
                data = search_naver_blog(query, start=start)
                for item in data['items']:
                    title = re.sub("<[^>]*>", "", item['title'])
                    desc = re.sub("<[^>]*>", "", item['description'])
                    link = item['link']
                    all_posts.append({
                        "region": region,
                        "category": cat,
                        "title": title,
                        "description": desc,
                        "link": link
                    })
                sleep(0.7)
            except Exception as e:
                print(f"âš ï¸ {query} {start} ì‹¤íŒ¨: {e}")
                break
        sleep(1.5)

    df = pd.DataFrame(all_posts)
    os.makedirs("data", exist_ok=True)
    df.to_csv("data/naver_blog_bigdata.csv", index=False, encoding="utf-8-sig")
    print(f"\nâœ… ì´ {len(df)}ê±´ ì €ì¥ ì™„ë£Œ (data/naver_blog_bigdata.csv)")
