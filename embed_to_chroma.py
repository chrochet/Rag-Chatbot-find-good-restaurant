import os
import sys
import pandas as pd
from dotenv import load_dotenv

from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


def build_chroma(csv_path: str, persist_directory: str) -> None:
    df = pd.read_csv(csv_path)

    # ğŸ”¹ ë°ì´í„° í™•ì¸
    required_cols = ["title", "description", "description_clean", "score", "label", "extracted_name"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(
            f"âŒ CSV íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\n"
            f"- ëˆ„ë½ëœ ì»¬ëŸ¼: {missing}\n"
            f"- í•„ìš”í•œ ì»¬ëŸ¼ ì „ì²´: {required_cols}"
        )

    # ğŸ”¹ ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„±
    df["search_text"] = (
        df["title"].fillna("").astype(str) + " " +
        df["description"].fillna("").astype(str) + " " +
        df["description_clean"].fillna("").astype(str)
    )

    # ğŸ”¹ í…ìŠ¤íŠ¸ ë¶„í• ê¸° (RAGìš©)
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)

    # ğŸ”¹ ë©”íƒ€ë°ì´í„° ìƒì„± (NaN â†’ "")
    metadatas = [
        {"score": s, "label": l, "extracted_name": en}
        for s, l, en in zip(
            df["score"],
            df["label"],
            df["extracted_name"].fillna("").astype(str)
        )
    ]

    docs = splitter.create_documents(
        texts=df["search_text"].tolist(),
        metadatas=metadatas
    )

    # ğŸ”¹ OpenAI ì„ë² ë”© ëª¨ë¸
    if not OPENAI_API_KEY:
        raise ValueError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. (.env í™•ì¸)")

    emb = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=OPENAI_API_KEY,
    )

    # ğŸ”¹ ChromaDBì— ì €ì¥
    db = Chroma.from_documents(
        documents=docs,
        embedding=emb,
        persist_directory=persist_directory,
    )

    # ë²„ì „ì— ë”°ë¼ persistê°€ ìˆì„ ìˆ˜ë„/ì—†ì„ ìˆ˜ë„ ìˆì–´ì„œ ë°©ì–´
    if hasattr(db, "persist"):
        db.persist()

    print(f"âœ… ChromaDB êµ¬ì¶• ë° ì €ì¥ ì™„ë£Œ ({len(df)}ê±´ ì €ì¥ë¨)")
    print(f"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {persist_directory}/")


if __name__ == "__main__":
    # âœ… í¸ì˜ ê¸°ëŠ¥:
    # - ì¸ì 1ê°œ: csv_pathë§Œ ì£¼ë©´ persist_directoryëŠ” ê¸°ë³¸ê°’ vectordb4
    # - ì¸ì 2ê°œ: csv_path + persist_directory (ê¸°ì¡´ ë°©ì‹)
    if len(sys.argv) == 2:
        csv_path = sys.argv[1]
        persist_directory = "vectordb4"
        print("â„¹ï¸ ì €ì¥ ë””ë ‰í† ë¦¬ë¥¼ ì…ë ¥í•˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ 'vectordb4'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        print(f"   ì˜ˆ) python embed_to_chroma.py {csv_path} vectordb4")

    elif len(sys.argv) == 3:
        csv_path = sys.argv[1]
        persist_directory = sys.argv[2]

    else:
        print("ì‚¬ìš©ë²•: python embed_to_chroma.py <csv_ê²½ë¡œ> [ì €ì¥_ë””ë ‰í† ë¦¬]")
        print("ì˜ˆì‹œ1: python embed_to_chroma.py data/naver_blog_bigdata_cleaned4.csv")
        print("ì˜ˆì‹œ2: python embed_to_chroma.py data/naver_blog_bigdata_cleaned4.csv vectordb4")
        sys.exit(1)

    if not os.path.exists(csv_path):
        print(f"âŒ {csv_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess_data.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        sys.exit(1)

    os.makedirs(persist_directory, exist_ok=True)
    build_chroma(csv_path, persist_directory)
